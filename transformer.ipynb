{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c4541a4-f885-445d-b46c-a79c4d568698",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7b60224-945e-42dc-87ba-ac3077836598",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('/data/datasets/mimic3_18var/root/in-hospital-mortality/train_listfile.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2c3e6fd-0804-409d-9221-392e928ac668",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stay</th>\n",
       "      <th>y_true</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>44856_episode1_timeseries.csv</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4016_episode2_timeseries.csv</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20671_episode1_timeseries.csv</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>72867_episode1_timeseries.csv</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31031_episode1_timeseries.csv</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14676</th>\n",
       "      <td>22128_episode1_timeseries.csv</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14677</th>\n",
       "      <td>86158_episode2_timeseries.csv</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14678</th>\n",
       "      <td>10577_episode1_timeseries.csv</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14679</th>\n",
       "      <td>9798_episode1_timeseries.csv</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14680</th>\n",
       "      <td>7110_episode1_timeseries.csv</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14681 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                stay  y_true\n",
       "0      44856_episode1_timeseries.csv       0\n",
       "1       4016_episode2_timeseries.csv       0\n",
       "2      20671_episode1_timeseries.csv       0\n",
       "3      72867_episode1_timeseries.csv       0\n",
       "4      31031_episode1_timeseries.csv       1\n",
       "...                              ...     ...\n",
       "14676  22128_episode1_timeseries.csv       0\n",
       "14677  86158_episode2_timeseries.csv       1\n",
       "14678  10577_episode1_timeseries.csv       0\n",
       "14679   9798_episode1_timeseries.csv       0\n",
       "14680   7110_episode1_timeseries.csv       0\n",
       "\n",
       "[14681 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54631813-513b-4184-bda6-98c381d40faf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample_path = train_data['stay'][1]\n",
    "data_dir = \"/data/datasets/mimic3_18var/root/in-hospital-mortality/train/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0db54be6-0909-477c-a461-bf91614db566",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample_path = data_dir + sample_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0968a8c-27a5-4859-86f3-2063b8c41521",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1cf5f143-a30a-4505-8663-ed5b84733ef7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(sample_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7bb88a1-c4b3-4316-baef-df2b346d624f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Hours', 'CO2 (ETCO2, PCO2, etc.)', 'Capillary refill rate',\n",
      "       'Diastolic blood pressure', 'Fraction inspired oxygen',\n",
      "       'Glascow coma scale eye opening', 'Glascow coma scale motor response',\n",
      "       'Glascow coma scale total', 'Glascow coma scale verbal response',\n",
      "       'Glucose', 'Heart Rate', 'Height', 'Mean blood pressure',\n",
      "       'Oxygen saturation', 'Respiratory rate', 'Systolic blood pressure',\n",
      "       'Temperature', 'Weight', 'pH'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7e98b5-4e26-4460-9d43-328834664a38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SinusoidalEmbedding(nn.Module):\n",
    "    def __init__(self, embedding_dim):\n",
    "        super(SinusoidalEmbedding, self).__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "\n",
    "    def forward(self, input_hours):\n",
    "        # Calculate sinusoidal embedding\n",
    "        position = torch.arange(0, self.embedding_dim, dtype=torch.float32).unsqueeze(0)\n",
    "        div_term = torch.exp(torch.arange(0, self.embedding_dim, 2, dtype=torch.float32) * -(np.log(10000.0) / self.embedding_dim))\n",
    "        \n",
    "        # Calculate sine and cosine terms\n",
    "        sin_terms = torch.sin(input_hours.unsqueeze(-1) * div_term)\n",
    "        cos_terms = torch.cos(input_hours.unsqueeze(-1) * div_term)\n",
    "\n",
    "        # Interleave sine and cosine terms\n",
    "        sinusoidal_embedding = torch.empty(input_hours.size(0), self.embedding_dim, dtype=torch.float32)\n",
    "        sinusoidal_embedding[:, 0::2] = sin_terms\n",
    "        sinusoidal_embedding[:, 1::2] = cos_terms\n",
    "        return sinusoidal_embedding\n",
    "\n",
    "# Example usage\n",
    "embedding_dim = 64  # You can adjust this based on your requirements\n",
    "sinusoidal_embedding = SinusoidalEmbedding(embedding_dim)\n",
    "\n",
    "# Input in hours (assuming 24 hours in a day)\n",
    "input_hours = torch.tensor([0, 6, 12, 18], dtype=torch.float32)\n",
    "output_embedding = sinusoidal_embedding(input_hours)\n",
    "\n",
    "print(\"Input hours:\", input_hours)\n",
    "print(\"Sinusoidal Embedding:\")\n",
    "print(output_embedding.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22cd0655-8833-4029-8afb-7be2e2262d17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_embedding[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2441b99-87e7-489e-8ebd-b86ed32bf9e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['Glascow coma scale motor response'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35652a9-7386-4dab-b6cc-6a7539d880d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['Glascow coma scale verbal response'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e00f01-5544-46bb-a6e3-3d48cc35a2f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "id_name_dict = {}\n",
    "# df.drop(labels=categorical_variables, axis=1, inplace=True)\n",
    "for i in range(len(df.columns)):\n",
    "    id_name_dict[i] = df.columns[i]\n",
    "values = df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dcb1d1a-0729-4919-a2f9-5657040c84a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "name_id_dict = {v:k for k,v in id_name_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716df728-d4f2-4d54-9c16-6bc2213a51b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "categorical_variables = ['Glascow coma scale eye opening', \n",
    "                                 'Glascow coma scale motor response', \n",
    "                                 'Glascow coma scale verbal response']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92db789-f33a-4c6e-bac7-c307a9b9bb88",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.drop(labels=categorical_variables, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfdbda59-a573-41ff-8141-f9618b6fec80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "id_name_dict = {}\n",
    "\n",
    "for i in range(len(df.columns)):\n",
    "    id_name_dict[i] = df.columns[i]\n",
    "values = df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a67f506-caf3-4163-b8d1-2522cf0b9154",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample = [[],[],[],[]]\n",
    "for i in range(values.shape[0]):\n",
    "    time = values[i,0]\n",
    "    for j in range(1, values.shape[1]):\n",
    "        try :\n",
    "            np.isnan(values[i][j])\n",
    "        except:\n",
    "            print(values[i][j])\n",
    "        if np.isnan(values[i][j]) == False:\n",
    "            sample[0].append(time)\n",
    "            sample[1].append(values[i][j])\n",
    "            sample[2].append(j)\n",
    "            sample[3].append(id_name_dict[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136d3401-7aba-4de2-afad-4b19a2ecaae5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "max(sample[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d11827-dd09-4004-8d76-ad315c90867b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "categorical_variables = ['Glascow coma scale eye opening', \n",
    "                                 'Glascow coma scale motor response', \n",
    "                               'Glascow coma scale verbal response']\n",
    "from tqdm import tqdm\n",
    "cat_set_list = []\n",
    "for cat in categorical_variables:\n",
    "    cat_set = set()\n",
    "    for sample_path in tqdm(train_data['stay']):\n",
    "        sample_path = data_dir + sample_path\n",
    "        df = pd.read_csv(sample_path)\n",
    "        df.fillna(0, inplace=True)\n",
    "        cat_set = cat_set.union(set(df[cat].unique()))\n",
    "    cat_set_list.append(cat_set)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5bce59c-4c17-4c20-8b11-c64c8c020598",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cat_set_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6d8b89-3ba3-4cf1-9b80-e93134c9b823",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cat_set_list[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd0cfdc-3036-42f8-9816-9b6236ce09e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cat_set_list[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545d2c49-4ea1-4df1-a8a0-7b58ae008cdf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cat_set_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fc48d0-99a2-4ee3-ba48-af641ab379c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799df43a-b2ea-41d1-b4b5-889562b6c48f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "138c4029-e306-4a9a-a65c-2bb6c0658dcc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.set_option('future.no_silent_downcasting',True)\n",
    "from tqdm import tqdm\n",
    "def isNAN(x):\n",
    "    return x!=x\n",
    "def get_mean_var(data, data_dir):\n",
    "    categorical_variables = ['Glascow coma scale eye opening', \n",
    "                                 'Glascow coma scale motor response', \n",
    "                                 'Glascow coma scale verbal response']\n",
    "    sample_path = data_dir + data['stay'][0]\n",
    "    id_name_dict = {}\n",
    "    df = pd.read_csv(sample_path)\n",
    "    df.drop(labels=categorical_variables, axis=1, inplace=True)\n",
    "    for i in range(len(df.columns)):\n",
    "        id_name_dict[i] = df.columns[i]\n",
    "    variable_values = {k : [] for k in df.columns[1:]}\n",
    "    for sample_path in tqdm(data['stay']):\n",
    "        sample_path = data_dir+sample_path\n",
    "        df = pd.read_csv(sample_path)\n",
    "        values = df.values\n",
    "        df.drop(labels=categorical_variables, axis=1, inplace=True)\n",
    "        df.replace(['ERROR','no data','.','-'], np.nan, inplace=True)\n",
    "        cols = df.columns[1:]\n",
    "        # print(len(cols))\n",
    "        df = df[cols]\n",
    "        values = df.values\n",
    "        # print(values.shape)\n",
    "        # print(len(id_name_dict))\n",
    "        for i in range(values.shape[0]):\n",
    "            for j in range(values.shape[1]):\n",
    "                \n",
    "                if isNAN((values[i][j])) == False:\n",
    "                    variable_values[id_name_dict[j+1]].append(float(values[i][j]))\n",
    "    result_dict = {}\n",
    "    for feature, values in variable_values.items():\n",
    "        mean_value = np.mean(values)\n",
    "        variance_value = np.var(values)\n",
    "        result_dict[feature] = {'mean': mean_value, 'variance': variance_value}\n",
    "    return result_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6109132f-f007-498c-80e6-8c8b0ab13bf5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 14681/14681 [01:57<00:00, 124.69it/s]\n"
     ]
    }
   ],
   "source": [
    "result_dict = get_mean_var(train_data, data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "09651bb8-3716-4e6f-9d01-50d799c791ba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean', 'variance'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(result_dict['CO2 (ETCO2, PCO2, etc.)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c58179-1234-40ab-b364-2945b2f631cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(result_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0bb5d77-f6d7-47eb-bef7-9ac4396ac390",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "variable_values = {k : [] for k in df.columns[1:]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e32abe-c250-45ec-8176-7cabdef7592c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for sample_path in tqdm(train_data['stay']):\n",
    "    sample_path = data_dir+sample_path\n",
    "    df = pd.read_csv(sample_path)\n",
    "    df.drop(labels=categorical_variables, axis=1, inplace=True)\n",
    "    cols = df.columns[1:]\n",
    "    df = df[cols]\n",
    "    values = df.values\n",
    "    for i in range(values.shape[0]):\n",
    "        for j in range(values.shape[1]):\n",
    "            try :\n",
    "                np.isnan(values[i][j])\n",
    "            except:\n",
    "                print(values[i][j])\n",
    "            if np.isnan(values[i][j]) == False:\n",
    "                variable_values[id_name_dict[j+1]].append(values[i][j])\n",
    "    result_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b62f7c-8f7c-4e64-b1d0-fcc0ae86c73b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e73a32-d288-492f-9959-4aaec24c6b05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sns.distplot(variable_values['Capillary refill rate'], hist=True, bins = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae2c1a9-2df0-4653-8bf8-1d76fcc3f2ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "result_dict = {}\n",
    "for feature, values in variable_values.items():\n",
    "    mean_value = np.mean(values)\n",
    "    variance_value = np.var(values)\n",
    "    result_dict[feature] = {'mean': mean_value, 'variance': variance_value}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8679ef69-6573-4582-ae83-fde8b3d72c46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d67480-6ea3-4bba-95cf-4e77323ff847",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "variable_values['pH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f585c4a0-8ce3-4c76-9192-0f441ebbff21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.mean(variable_values['Capillary refill rate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526cc25b-809c-4001-bdaa-35aa845125dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.std(variable_values['Capillary refill rate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0b8146-01cd-46f1-8271-8730d30605ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.max(variable_values['Capillary refill rate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1612431-0897-406d-befd-534133e0f383",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.min(variable_values['Capillary refill rate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e48d394-b020-4493-8bc9-6bd1af467662",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MimicDataSetInHospitalMortality(Dataset):\n",
    "    def __init__(self, data_dir, csv_file, mean_variance, mode, seq_len, pad_value = 0, device = DEVICE):\n",
    "        super().__init__() \n",
    "        self.data_dir = data_dir\n",
    "        self.csv_file = csv_file\n",
    "        self.seq_len = seq_len\n",
    "        self.mode = mode\n",
    "        self.data_df = pd.read_csv(csv_file)\n",
    "        self.mean_variance = mean_variance\n",
    "        self.pad_value = pad_value\n",
    "        self.device = device\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data_df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        path = self.data_dir + self.data_df['stay'][idx]\n",
    "        data = pd.read_csv(path)\n",
    "        categorical_variables = ['Glascow coma scale eye opening', \n",
    "                                 'Glascow coma scale motor response', \n",
    "                                 'Glascow coma scale verbal response']\n",
    "        id_name_dict = {}\n",
    "        \n",
    "        data.drop(labels=categorical_variables, axis=1, inplace=True)\n",
    "        \n",
    "        # for col in categorical_variables:\n",
    "        #     print(data[col].unique())\n",
    "        #     data[col] = data[col].apply(lambda x : float(x.split()[0]) if str(x)==x else x)\n",
    "\n",
    "        for i in range(len(data.columns)):\n",
    "            id_name_dict[i] = data.columns[i]\n",
    "        values = data.values\n",
    "        sample = self.extract(values, id_name_dict)\n",
    "        # print(len(sample[0]))\n",
    "        if len(sample[0]) >= self.seq_len :\n",
    "            sample[0] = sample[0][-self.seq_len:]\n",
    "            sample[1] = sample[1][-self.seq_len:]\n",
    "            sample[2] = sample[2][-self.seq_len:]\n",
    "            sample[3] = sample[3][-self.seq_len:]\n",
    "        num_padd_tokens = self.seq_len - len(sample[0])\n",
    "        \n",
    "        variable_input = torch.cat([\n",
    "            torch.tensor(sample[2], dtype=torch.int64),\n",
    "            torch.tensor([self.pad_value]*num_padd_tokens, dtype=torch.int64)\n",
    "        ])\n",
    "        value_input = torch.cat([\n",
    "            torch.tensor(sample[1], dtype=torch.float),\n",
    "            torch.tensor([self.pad_value]*num_padd_tokens, dtype=torch.float)\n",
    "        ])\n",
    "        val = torch.tensor(sample[0], dtype=torch.float)\n",
    "        # print(val)\n",
    "        # print(val.min())\n",
    "        time_input = torch.cat([\n",
    "             val - val.min() ,\n",
    "            torch.tensor([self.pad_value]*num_padd_tokens, dtype=torch.float)\n",
    "        ])\n",
    "        variables = sample[3] + ['pad token']*num_padd_tokens\n",
    "        \n",
    "        # print(variable_input.shape)\n",
    "        # print(value_input.shape)\n",
    "        # print(time_input.shape)\n",
    "        # print(len(variables))\n",
    "        assert variable_input.size(0) == self.seq_len\n",
    "        assert value_input.size(0) == self.seq_len\n",
    "        assert time_input.size(0) == self.seq_len\n",
    "        \n",
    "        return {\n",
    "            \"encoder_input\" : [time_input.to(self.device), variable_input.to(self.device), value_input.to(self.device)],\n",
    "            \"encoder_mask\": (variable_input != self.pad_value).unsqueeze(0).int().to(self.device),\n",
    "            \"variables\" : variables,\n",
    "            \"label\" : torch.tensor([self.data_df['y_true'][idx]], dtype=torch.int64).to(self.device)\n",
    "        }\n",
    "    \n",
    "    def extract(self, values, id_name_dict):\n",
    "        sample = [[],[],[],[]]\n",
    "        start_time = values[0,0]\n",
    "        for i in range(values.shape[0]):\n",
    "            time = values[i,0]\n",
    "            for j in range(1, values.shape[1]):\n",
    "                try :\n",
    "                    np.isnan(values[i][j])\n",
    "                except:\n",
    "                    print(values[i][j])\n",
    "                if np.isnan(values[i][j]) == False:\n",
    "                    sample[0].append(time)\n",
    "                    mean = self.mean_variance[id_name_dict[j]]['mean']\n",
    "                    std = self.mean_variance[id_name_dict[j]]['variance']**0.5\n",
    "                    sample[1].append((values[i][j]-mean)/std)\n",
    "                    sample[2].append(j)\n",
    "                    sample[3].append(id_name_dict[j])\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3af8a74-63bd-4f25-a99a-7b7269148168",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a14e28-6c8f-4ee8-8e68-e7ede2492b39",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# lengths = []\n",
    "# MAX_LEN = 0\n",
    "# for data_path in tqdm(train_data['stay']):\n",
    "#     path = data_dir+data_path\n",
    "#     df = pd.read_csv(path)\n",
    "#     l = (df.isnull() == False).sum().sum()\n",
    "#     lengths.append((df.isnull() == False).sum().sum())\n",
    "#     if l > MAX_LEN:\n",
    "#         MAX_LEN = l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027fb712-b83a-4667-a182-e1cd3a263361",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# MAX_LEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d18908a-b45d-45b4-9776-f509ad20f5c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MAX_LEN = 22048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7f59bd-df86-400a-a06d-d3222b03315b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# plt.hist(lengths, bins='auto', alpha=0.7, color='blue', edgecolor='black')\n",
    "\n",
    "# # Add labels and title\n",
    "# plt.xlabel('Lengths')\n",
    "# plt.ylabel('Frequency')\n",
    "# plt.title('Distribution of Lengths')\n",
    "\n",
    "# # Show the plot\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62435e3e-fa9f-4367-9341-f004346e1214",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MAX_LEN = 25 # donot change this\n",
    "batch_size = 32\n",
    "d_model = 32\n",
    "num_heads = 4\n",
    "N = 2\n",
    "num_variables = 14 \n",
    "num_variables+=1 #for no variable embedding while doing padding\n",
    "d_ff = 64\n",
    "epochs = 1\n",
    "learning_rate = 3e-4\n",
    "drop_out = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7abecdd3-78ca-438a-bf84-acf4d490ad98",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data_path = \"/data/datasets/mimic3-benchmarks/data/in-hospital-mortality/train_listfile.csv\"\n",
    "val_data_path = \"/data/datasets/mimic3-benchmarks/data/in-hospital-mortality/val_listfile.csv\"\n",
    "\n",
    "data_dir = \"/data/datasets/mimic3-benchmarks/data/in-hospital-mortality/train/\"\n",
    "\n",
    "mean_variance = get_mean_var(pd.read_csv(train_data_path), data_dir)\n",
    "\n",
    "train_ds = MimicDataSetInHospitalMortality(data_dir, train_data_path, mean_variance, 'training', MAX_LEN)\n",
    "val_ds = MimicDataSetInHospitalMortality(data_dir, val_data_path, mean_variance, 'validation', MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4bd382a-70a9-4a8a-af42-2e9b6116ded4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_ds, batch_size = batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_ds, batch_size = batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7190ad4f-7d98-4454-a83f-0e6a6a7effb3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "for batch in tqdm(train_dataloader):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b4d49e-44b8-48f1-a9f2-87cceda80999",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch['encoder_input'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3575a66-9a76-4c8c-ace9-8101189f50fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch['encoder_input'][0].min(axis=1).values.unsqueeze(1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6fd0308-40f2-4dd3-8200-9842260a18f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch['encoder_input'][0] - batch['encoder_input'][0].min(axis=1).values.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e2e7ee-db32-4e34-a30f-f7b2558dca67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch['encoder_input'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9833fe35-9870-46bb-aa05-c6d4d9620c57",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch['encoder_input'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522c1718-b6f5-46f9-bd37-91332ab0dc3b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch['encoder_mask'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83df235-87f6-45e3-916e-8cdf53709b32",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch['label'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3504615d-b999-4f3c-b456-58ffd1875c03",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ContinuousValueEmbedding(nn.Module):\n",
    "    def __init__(self, d_model):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Linear(1, d_model)\n",
    "        self.tanh = nn.Tanh()\n",
    "    def forward(self, x):\n",
    "        out = self.embedding(x.unsqueeze(2))\n",
    "        out = self.tanh(out)\n",
    "        return out\n",
    "    \n",
    "class VariableEmbedding(nn.Module):\n",
    "    def __init__(self, d_model, num_variables):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(num_variables+1, d_model)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.embedding(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49429f68-d188-4b50-91a2-c0678a25c87d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cvs = ContinuousValueEmbedding(d_model).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb83bce-3bc3-4c4c-a89a-0be53705bd3d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "time_input = batch['encoder_input'][0]\n",
    "variable_input = batch['encoder_input'][1]\n",
    "value_input = batch['encoder_input'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3d3160-51fa-4927-887b-915f36ddf0c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "value_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357aec0c-20ed-4e7e-9b35-484395413e84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cvs.forward(value_input).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a722b122-9c25-4052-a078-8c087890a7d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "value_embedding = cvs.forward(value_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93130c89-4226-453c-a79a-44e5f016faec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cvs.forward(time_input).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be21a191-40cf-48a3-8c9b-ae2b2311d975",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "time_embedding = cvs.forward(time_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96dfd2b1-b592-4208-95cc-a69d8f9918c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "time_embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d3b58d-bdfb-49fa-a06e-6b1b48bd5dea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "varembed = VariableEmbedding(d_model, num_variables).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d43a72-68f9-4e80-a216-cdde8c254838",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "varembed.forward(variable_input).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dda051a-70d5-40c4-948d-efcb805960a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "variable_embedding = varembed.forward(variable_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65ae1d8-5db4-494f-a5ae-c5d8b636ddb6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "variable_embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fc2a57-c05b-4c29-b5db-c64db1eb91f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Embedding(nn.Module):\n",
    "    def __init__(self, d_model, num_variables):\n",
    "        super().__init__()\n",
    "        self.cvs_value = ContinuousValueEmbedding(d_model)\n",
    "        self.cvs_time = ContinuousValueEmbedding(d_model)\n",
    "        self.var_embed = VariableEmbedding(d_model, num_variables)\n",
    "    def forward(self, encoder_input):\n",
    "        time = encoder_input[0]\n",
    "        variable = encoder_input[1]\n",
    "        value = encoder_input[2]\n",
    "        embed = self.cvs_time(time) + self.cvs_value(value) + self.var_embed(variable)\n",
    "        return embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea040a63-0728-458e-adbb-32b11df2abde",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "embedding = Embedding(d_model, num_variables).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf400d0c-1267-493e-8e78-e79777f7acf5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "embedding.forward(batch['encoder_input']).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35eb681-da2e-425d-a4a4-96b3fce97797",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "embed = embedding.forward((time_input, variable_input, value_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b321269-d259-4e40-a8be-fb281e64fb4b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "embed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd82b25-c22e-4508-bfb7-a3a8e96126dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, d_model, d, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.d = d\n",
    "        self.Q = nn.Linear(d_model, d)\n",
    "        self.K = nn.Linear(d_model, d)\n",
    "        self.V = nn.Linear(d_model, d)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    def forward(self,x, mask): #inp --> (64, 256, d_model)\n",
    "        q = self.Q(x) #(64, 256, d)\n",
    "        k = self.K(x) #(64, 256, d)\n",
    "        v = self.V(x) #(64, 256, d)\n",
    "        # print(q.shape)\n",
    "        weights = q@k.transpose(-2,-1)*k.shape[-1]**(-0.5) #(64, 256, 256) \n",
    "        # print(weights.shape)\n",
    "        # weights = weights.masked_fill(torch.logical_or(mask == 0, (mask.transpose(-2, -1) == 0)), float('-inf'))\n",
    "        weights = weights.masked_fill(mask == 0, float('-inf'))\n",
    "        # print(weights)\n",
    "        weights = F.softmax(weights, dim = -1) #(64, 256, 256)\n",
    "        self.dropout(weights)\n",
    "        out = weights @ v\n",
    "        return out #(64, 256, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849d293a-d1c6-4c1a-ad9d-69a59c0625de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "attn = Attention(d_model, 8).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02436817-9819-40a7-9d70-df1dcbd659b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "attn_out = attn.forward(embed, batch['encoder_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36fe96a-fe28-45a8-a981-195df2a47363",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "attn_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dff7707-1238-491f-8bd2-64f1019c26d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, n_heads, dropout = 0.2):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([Attention(d_model, d_model//n_heads) for _ in range(n_heads)])\n",
    "        self.proj = nn.Linear(n_heads*(d_model//n_heads), d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x, mask):\n",
    "        out = torch.cat([h(x, mask) for h in self.heads], dim=-1)\n",
    "        out = self.dropout(self.proj(out))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754cd4f5-007f-4692-b234-7ac1f0208df8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "m_att = MultiHeadAttention(d_model, 4).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ab7403-bab7-4fc1-830a-efd58a809963",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "matt_out = m_att(embed, batch['encoder_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba024210-0807-4b87-80a7-9e269d60db94",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "matt_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865257ff-b5a0-4150-828f-3aaa96305dda",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FeedForwardBlock(nn.Module):\n",
    "    def __init__(self, d_model, d_ff, dropout = 0.2):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.W1 = nn.Linear(d_model, d_ff)\n",
    "        self.W2 = nn.Linear(d_ff, d_model)\n",
    "    def forward(self, x):\n",
    "        out = self.W1(x)\n",
    "        out = F.relu(out)\n",
    "        out = self.dropout(self.W2(out))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de90db4e-696f-4356-a7c1-678767403429",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ffb = FeedForwardBlock(d_model, d_ff).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e958e1-902b-4a58-80d1-7ff1ba28f2b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ffb(matt_out).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e25d18e-47fd-4b83-8ac7-0ae7f4d16f0a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ffb_out = ffb(matt_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68dd4ee2-098a-4e33-aba7-d35719405e36",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EncoderBlock(nn.Module):\n",
    "    def __init__(self, d_model, n_heads, d_ff):\n",
    "        super().__init__()\n",
    "        self.multi_attention = MultiHeadAttention(d_model, n_heads)\n",
    "        self.ffb = FeedForwardBlock(d_model, d_ff)\n",
    "        self.ln1 = nn.LayerNorm(d_model)\n",
    "        self.ln2 = nn.LayerNorm(d_model)\n",
    "    \n",
    "    def forward(self, x, mask):\n",
    "        out = self.multi_attention(x, mask)\n",
    "        out1 = x + self.ln2(out)\n",
    "        out2 = self.ffb(out1)\n",
    "        out = out1 + self.ln2(out2)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb382db-0ed4-4806-8cea-b11533f4908a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "encoder_block = EncoderBlock(d_model, num_heads, d_ff).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24f961f-baaa-4048-8bf7-e1a500c00f3d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "out = encoder_block(embed, batch['encoder_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16223d03-c46d-4107-ae70-039f15929443",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9977c70-14be-4920-ab64-d5f7754ba40f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, d_model, n_heads, d_ff, num_variables , N):\n",
    "        super().__init__()\n",
    "        self.embedding = Embedding(d_model, num_variables)\n",
    "        self.encoder_blocks = nn.ModuleList([EncoderBlock(d_model, n_heads, d_ff) for _ in range(N)])\n",
    "        self.N = N\n",
    "    \n",
    "    def forward(self, encoder_input, mask):\n",
    "        time = encoder_input[0]\n",
    "        variable = encoder_input[1]\n",
    "        value = encoder_input[2]\n",
    "        x = self.embedding((time, variable, value))\n",
    "        for block in self.encoder_blocks:\n",
    "            x = block(x, mask)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb441210-335d-4466-a10c-f78008868d0c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "encoder = Encoder(d_model, num_heads, d_ff, num_variables, N).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2364682e-f3b9-4dba-9152-99fd5e2d9f4f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "enc_out = encoder.forward(embed, batch['encoder_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227c9ad3-d0d8-4cb4-86d6-019a91ae2a28",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FusionSelfAttention(nn.Module):\n",
    "    def __init__(self, d_model, dropout = 0.2):\n",
    "        super().__init__()\n",
    "        self.Wa = nn.Linear(d_model, d_model)\n",
    "        self.Ua = nn.Linear(d_model, d_model)\n",
    "        self.Va = nn.Linear(d_model, 1)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        \n",
    "    def forward(self, out, mask):\n",
    "        q = out.unsqueeze(2) #(4, 100, 1,  32)\n",
    "        k = out.unsqueeze(1) #(4, 1, 100, 32)\n",
    "        v = out #(4, 100, 32)\n",
    "        a = F.tanh(self.Wa(q) + self.Ua(k)) #(4, 100, 100, 32)\n",
    "        # print(a.shape)\n",
    "        wei = self.Va(self.dropout(a)).squeeze()#(4, 100, 100)\n",
    "        # print(wei.shape)\n",
    "        wei = wei.masked_fill(mask == 0, float('-inf'))\n",
    "        wei = F.softmax(wei, dim = -1)\n",
    "        wei = self.dropout(wei)\n",
    "        out = wei@v\n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e9e2f2-2066-40cc-8442-3f9f86088f36",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fsa = FusionSelfAttention(d_model).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8c8384-8803-4844-9044-4ed3fafbec0e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fsa(enc_out, batch['encoder_mask']).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0f9073-1d9b-4a97-b7b2-5cb7004329d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, d_model, n_heads, d_ff, num_variables, N):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(d_model, n_heads, d_ff, num_variables, N)\n",
    "        self.fsa = FusionSelfAttention(d_model)\n",
    "        self.proj = nn.Linear(d_model, 1)\n",
    "    \n",
    "    def forward(self, x, mask):\n",
    "        out = self.encoder(x, mask)\n",
    "        out = self.fsa(out, mask)\n",
    "        out = out.masked_fill(mask.transpose(-2,-1)==0, 0)\n",
    "        out = out.sum(dim = 1)\n",
    "        out = self.proj(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267c10a9-c56a-4f98-bc14-1762db82ddbb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = Model(d_model, num_heads, d_ff, num_variables, N).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7f311c-33cc-48e0-9d14-6ed29f44d719",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f'Total number of parameters: {total_params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0749fb1-3b3e-4087-956e-40a8b9efea1f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model(batch['encoder_input'], batch['encoder_mask']).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1152861-b31b-486f-a043-d04ce0527c63",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from sklearn.metrics import roc_auc_score\n",
    "# def eval():\n",
    "#     model.eval()\n",
    "#     all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c01e01-3103-4ca8-8e69-a1a8a15885c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "model = Model(d_model, num_heads, d_ff, num_variables, N).to(DEVICE)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for batch in tqdm(train_dataloader, desc=f'Epoch {epoch + 1}/{epochs}', leave=False):\n",
    "        outputs = model(batch['encoder_input'], batch['encoder_mask'])\n",
    "        loss = criterion(outputs, batch['label'].float().view(-1,1))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f'Epoch {epoch + 1}/{epochs}, Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0623c091-829d-4ced-8542-f6e78c9b74be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def calculate_roc_auc(model, data_loader):\n",
    "    model.eval()\n",
    "    all_probabilities = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs in tqdm(data_loader, leave=False):\n",
    "            outputs = model(inputs['encoder_input'], inputs['encoder_mask'])\n",
    "            labels = inputs['label']\n",
    "            logits = torch.sigmoid(outputs)\n",
    "            \n",
    "            all_probabilities.append(logits.cpu().numpy())\n",
    "            all_labels.append(labels.cpu().numpy())\n",
    "\n",
    "    logits_all = np.concatenate(all_probabilities)\n",
    "    labels_all = np.concatenate(all_labels)\n",
    "    \n",
    "    roc_auc = roc_auc_score(labels_all, logits_all)\n",
    "    return roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4881e9-8061-45e9-942b-c1f33a7e2138",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "calculate_roc_auc(model, val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c959583d-504b-4239-ba28-9048c4b81d32",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "file_path = \"/data/datasets/mimic3-benchmarks/data/in-hospital-mortality/train/listfile.csv\"\n",
    "\n",
    "files = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae71c9df-10a3-4f79-9693-7ba00258d851",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482a798c-5513-4d45-becc-816fe453b3de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "zero_indices = files[files['y_true'] == 0].index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5cd31ca-80c4-4798-b00f-92b75ff26fd1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(zero_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8847f601-d98c-440a-8620-6fce2da8bfb5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "one_indices = files[files['y_true'] == 1].index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a50ca6e-1bc8-452d-a683-76a8dd036250",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(one_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c3ad43-e706-42a0-bead-ff1036d6b8f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.random.shuffle(zero_indices)\n",
    "np.random.shuffle(one_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd4c683-4f5a-47ff-b026-ec072b28da31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_size = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940daddc-cb2e-4a4c-9306-e79705778c02",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "N = int(len(zero_indices)*train_size)\n",
    "train_zero_indices = zero_indices[:N]\n",
    "val_zero_indices = zero_indices[N:]\n",
    "\n",
    "N = int(len(one_indices)*train_size)\n",
    "train_one_indices = one_indices[:N]\n",
    "val_one_indices = one_indices[N:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29c2129-f180-46a9-b75e-25fd1a16e250",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_zero_data = files.iloc[train_zero_indices,:]\n",
    "val_zero_data = files.iloc[val_zero_indices,:]\n",
    "train_one_data = files.iloc[train_one_indices,:]\n",
    "val_one_data = files.iloc[val_one_indices,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8823b1f8-fa7f-4ca6-a35a-a7f812a64660",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_list_file = pd.concat([train_one_data, train_zero_data]).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50455222-ea86-481f-9433-d0f24dce3af4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "val_list_file = pd.concat([val_one_data, val_zero_data]).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5959e2a-f538-485b-ab11-8ba7f35edfb2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_indices = list(range(len(train_list_file)))\n",
    "val_indices = list(range(len(val_list_file)))\n",
    "\n",
    "np.random.shuffle(train_indices)\n",
    "np.random.shuffle(val_indices)\n",
    "\n",
    "train_list_file = train_list_file[train_indices][:]\n",
    "val_list_file = val_list_file[val_indices][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f41988-1afd-4df0-a2b1-8d786867e4a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_list_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de78828-0526-4296-94e5-c7f91245b41f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "val_list_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a394e9-c57f-4796-8d44-25f80286fcf5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_list_file.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89850b6-5202-4189-b715-d66163a37192",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "val_list_file.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2cc4109-ef41-4e98-ac7b-ffd9218ba331",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_list_file = pd.DataFrame(train_list_file,columns=['stay', 'y_true'])\n",
    "val_list_file = pd.DataFrame(val_list_file,columns=['stay', 'y_true'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27ec655-fdc0-4f25-a415-1fc3b853ff46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_list_file.to_csv(f\"{data_dir}/train_listfile.csv\", index = False)\n",
    "val_list_file.to_csv(f\"{data_dir}/val_list_file.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54e10a6-4ddd-4e66-a9b5-8647224b5b78",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "val_list_file.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52f5ee0-e501-43be-9f0a-29cdf19aad2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 448\n",
    "batch_size = 32\n",
    "d_model = 50\n",
    "num_heads = 4\n",
    "N = 2\n",
    "num_variables = 17 \n",
    "num_variables += 1 #for no variable embedding while doing padding\n",
    "d_ff = 100\n",
    "epochs = 75\n",
    "learning_rate = 8e-4\n",
    "drop_out = 0.2\n",
    "sinusoidal = True\n",
    "import torch\n",
    "DEVICE = 'cpu'#'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from utils import MimicDataSetInHospitalMortality, calculate_roc_auc, calculate_auc_prc\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from model import Model\n",
    "from tqdm import tqdm\n",
    "from normalizer import Normalizer\n",
    "from categorizer import Categorizer\n",
    "\n",
    "train_data_path = \"/data/datasets/mimic3-benchmarks/data/in-hospital-mortality/train_listfile.csv\"\n",
    "val_data_path = \"/data/datasets/mimic3-benchmarks/data/in-hospital-mortality/val_listfile.csv\"\n",
    "\n",
    "data_dir = \"/data/datasets/mimic3-benchmarks/data/in-hospital-mortality/train/\"\n",
    "\n",
    "import pickle\n",
    "\n",
    "with open('normalizer.pkl', 'rb') as file:\n",
    "    normalizer = pickle.load(file)\n",
    "\n",
    "with open('categorizer.pkl', 'rb') as file:\n",
    "    categorizer = pickle.load(file)\n",
    "    \n",
    "\n",
    "mean_variance = normalizer.mean_var_dict\n",
    "cat_dict = categorizer.category_dict\n",
    "\n",
    "\n",
    "train_ds = MimicDataSetInHospitalMortality(data_dir, train_data_path, mean_variance, cat_dict, 'training', MAX_LEN)\n",
    "val_ds = MimicDataSetInHospitalMortality(data_dir, val_data_path, mean_variance, cat_dict, 'validation', MAX_LEN)\n",
    "\n",
    "train_dataloader = DataLoader(train_ds, batch_size = batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_ds, batch_size = 1, shuffle=True)\n",
    "\n",
    "model = Model(d_model, num_heads, d_ff, num_variables, N, sinusoidal).to(DEVICE)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f'Total number of parameters: {total_params}')\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for batch in tqdm(train_dataloader, desc=f'Epoch {epoch + 1}/{epochs}', leave=False):\n",
    "        inp = batch['encoder_input']\n",
    "        mask = batch['encoder_mask']\n",
    "        y = batch['label']\n",
    "        outputs = model(inp, mask)\n",
    "        loss = criterion(outputs, y.float().view(-1,1))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    # print(f'Epoch {epoch + 1}/{epochs}, Train AUC-ROC: {calculate_roc_auc(model, train_dataloader):.3f}')\n",
    "    print(f'Epoch {epoch + 1}/{epochs}, Validation AUC-ROC: {calculate_roc_auc(model, val_dataloader):.3f}')\n",
    "    print(f'Epoch {epoch + 1}/{epochs}, Validation AUC-PRC: {calculate_auc_prc(model, val_dataloader):.3f}')\n",
    "    \n",
    "\n",
    "# Constructing the file path\n",
    "file_path = f\"model_maxlen{MAX_LEN}_batch{batch_size}_dmodel{d_model}_heads{num_heads}_N{N}_vars{num_variables}_dff{d_ff}_epochs{epochs}_lr{learning_rate}_dropout{drop_out}_sinusoidal{sinusoidal}.pth\"\n",
    "\n",
    "# Example usage\n",
    "torch.save(model.state_dict(), \"models/\"+ file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfccbfbd-8d21-4f40-8d54-4e8b032238a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for batch in tqdm(train_dataloader):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8cfeb2f-1321-4e28-9c37-02d96c7d0553",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch['encoder_input'][2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2f60d2-d1bb-40f7-baab-6ccebf0dba4c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch['encoder_input'][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2cd647-97df-4ec7-9151-6bbd7a385b81",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch['encoder_input'][1].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4679a4-1adb-436a-a1e7-dc491c1e3ff7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch['encoder_input'][1].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214f8822-6ef6-4543-8c5d-0220d87c2fa8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mimic",
   "language": "python",
   "name": "mimic"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
